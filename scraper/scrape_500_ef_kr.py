"""
Svenska Krig Scraper - H√§ndelser efter 500 e.Kr.
================================================

OBS: Detta script √§r designat f√∂r att k√∂ras lokalt p√• din egen dator.
Det kr√§ver internet√•tkomst till Wikipedia, SO-rummet, Popul√§r Historia, etc.

Installation:
    pip install requests beautifulsoup4 pandas

Anv√§ndning:
    python sverige_krig_scraper.py

Output:
    krig_events.csv - CSV-fil med alla hittade h√§ndelser
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
from urllib.parse import quote

headers = {"User-Agent": "SverigeHistoria/1.0 (studentprojekt; kontakt@example.com)"}

events = []
seen = set()  # F√∂r att undvika dubletter

# Svenska st√§der och orter (bas-lista f√∂r matchning)
svenska_stader = [
    # Storst√§der
    'Stockholm', 'G√∂teborg', 'Malm√∂', 'Uppsala', 'Link√∂ping', '√ñrebro',
    'V√§ster√•s', 'Helsingborg', 'Norrk√∂ping', 'J√∂nk√∂ping', 'Lund', 'Ume√•',
    'G√§vle', 'Bor√•s', 'Eskilstuna', 'S√∂dert√§lje', 'Karlstad', 'V√§xj√∂',
    'Halmstad', 'Sundsvall', '√ñstersund', 'Trollh√§ttan', 'Lule√•', 'Borl√§nge',
    'Falun', 'Kalmar', 'Sk√∂vde', 'Karlskrona', 'Kristianstad', 'Skellefte√•',
    
    # Historiskt viktiga orter
    'Visby', 'Sigtuna', 'Birka', 'Gamla Uppsala', 'Vadstena', 'Str√§ngn√§s',
    'Nyk√∂ping', 'Arboga', 'Enk√∂ping', 'S√∂derk√∂ping', 'Skan√∂r', 'Falsterbo',
    'L√∂d√∂se', 'Kung√§lv', 'Marstrand', 'Bohus', '√Ñlvsborg', 'Varberg',
    'Falkenberg', 'Laholm', '√Ñngelholm', 'Landskrona', 'Trelleborg', 'Ystad',
    'Simrishamn', 'S√∂lvesborg', 'Karlshamn', 'Ronneby', 'Vimmerby', 'V√§stervik',
    'Oskarshamn', 'Nybro', 'Eksj√∂', 'Vetlanda', 'Tran√•s', 'Motala', 'Mj√∂lby',
    'Vadstena', 'Sk√§nninge', 'Askersund', 'Mariestad', 'Lidk√∂ping', 'Vara',
    'Alings√•s', 'Ulricehamn', 'Tidaholm', 'Falk√∂ping', 'Herrljunga',
    
    # Norrland
    'H√§rn√∂sand', '√ñrnsk√∂ldsvik', 'Sollefte√•', 'Kramfors', '√Önge', 'Timr√•',
    'Hudiksvall', 'S√∂derhamn', 'Bolln√§s', 'Ljusdal', 'Mora', 'Ludvika',
    'Avesta', 'Hedemora', 'S√§ter', 'Pite√•', 'Boden', 'Kalix', 'Haparanda',
    'Kiruna', 'G√§llivare', 'Jokkmokk', 'Arvidsjaur', 'Lycksele', 'Vilhelmina',
    'Storuman', 'Dorotea', 'Str√∂msund', 'Sveg', 'Fun√§sdalen',
    
    # Dalarna/Bergslagen
    'R√§ttvik', 'Leksand', 'Orsa', '√Ñlvdalen', 'Malung', 'Vansbro', 'Gagnef',
    'S√§len', 'Idre', 'Filipstad', 'Hagfors', 'Torsby', 'Sunne', 'Arvika',
    '√Öm√•l', 'Bengtsfors', 'Dals-Ed', 'Mellerud', 'V√§nersborg', 'Uddevalla',
    'Lysekil', 'Str√∂mstad', 'Tanum', 'Munkedal', 'Soten√§s', 'Orust',
    
    # Slag- och krigsplatser
    'Brunkeberg', 'St√•ngebro', 'St√§ket', 'Br√§nnkyrka', 'Gestilren', 'Lena',
    'Sparrs√§tra', 'Herrevadsbro', 'Ringsj√∂', 'Fotevik', 'D√ºnam√ºnde',
    'Kirkholm', 'Kircholm', 'Klisz√≥w', 'Fraustadt', 'Holowczyn',
    'Poltava', 'Fredrikshald', 'Narva', 'N√∂teborg', 'Dorpat',
    'Riga', 'Reval', 'Stralsund', 'Wismar', 'Stettin', 'Wolgast',
    'Usedom', 'R√ºgen', 'Greifswald', 'Rostock', 'L√ºbeck', 'Bremen',
    'Verden', 'Stade', 'Hamburg', 'Breitenfeld', 'L√ºtzen', 'N√∂rdlingen',
    'Rain', 'Ingolstadt', 'M√ºnchen', 'Augsburg', 'Ulm', 'Mainz', 'Worms',
    'Frankfurt', 'W√ºrzburg', 'Erfurt', 'Leipzig', 'Dresden', 'Prag',
    'Wien', 'Olm√ºtz', 'Br√ºnn', 'Jankow', 'Warschau', 'Krakow', 'Thorn',
    'Danzig', 'Elbing', 'K√∂nigsberg', 'Memel', 'Mitau', 'D√ºnaburg',
    
    # Landskap/regioner (som backup)
    'Sk√•ne', 'Halland', 'Blekinge', 'Sm√•land', '√ñland', 'Gotland',
    '√ñsterg√∂tland', 'V√§sterg√∂tland', 'Bohusl√§n', 'Dalsland', 'V√§rmland',
    'N√§rke', 'S√∂dermanland', 'Uppland', 'V√§stmanland', 'Dalarna',
    'G√§strikland', 'H√§lsingland', 'Medelpad', '√Öngermanland', 'J√§mtland',
    'H√§rjedalen', 'V√§sterbotten', 'Norrbotten', 'Lappland'
]

def extract_location(text):
    """Extrahera plats/stad fr√•n texten."""
    # F√∂rst leta efter k√§nda st√§der/platser
    for stad in svenska_stader:
        # Anv√§nd word boundary f√∂r att undvika delmatchningar
        pattern = r'\b' + re.escape(stad) + r'\b'
        if re.search(pattern, text, re.IGNORECASE):
            return stad
    
    # Om ingen k√§nd stad hittas, leta efter "i [Stad]" eller "vid [Stad]" m√∂nster
    location_patterns = [
        r'i\s+([A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+(?:\s+[A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+)?)',
        r'vid\s+([A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+(?:\s+[A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+)?)',
        r'n√§ra\s+([A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+(?:\s+[A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+)?)',
        r'utanf√∂r\s+([A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+(?:\s+[A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+)?)',
        r'mot\s+([A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+(?:\s+[A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+)?)',
    ]
    
    for pattern in location_patterns:
        match = re.search(pattern, text)
        if match:
            potential_location = match.group(1)
            # Filtrera bort vanliga ord som inte √§r platser
            skip_words = ['den', 'det', 'de', 'en', 'ett', 'och', 'eller', 'som', 'att', 'f√∂r', 'med', 'till', 'fr√•n', 'av', 'p√•', 'om', 'vid', 'efter', 'under', '√∂ver', 'mellan', 'genom', 'utan', 'inom', 'enligt', 'mot', 'hos', '√§n', 's√•', 'hur', 'var', 'n√§r', 'd√§r', 'hit', 'dit', 'upp', 'ner', 'ut', 'in', 'hem', 'bort', 'fram', 'igen', 'ocks√•', 'bara', 'nog', 'ju', 'v√§l', 'nog', '√§nd√•', 'allts√•', 'dock', 'alltid', 'aldrig', 'ofta', 's√§llan', 'ibland', 'kanske', 'troligen', 'f√∂rmodligen', 'antagligen', 's√§kert', 'verkligen', 'faktiskt', 'egentligen', 'ursprungligen', 'slutligen', 'tidigare', 'senare', 'sedan', 'redan', '√§nnu', 'fortfarande', 'hittills', 'numera', 'nuf√∂rtiden', 'f√∂rr', 'f√∂rut', 'nyligen', 'snart', 'strax', 'genast', 'omedelbart', 'pl√∂tsligt', 'gradvis', 'successivt', 'l√•ngsamt', 'snabbt', 'hastigt']
            if potential_location.lower() not in skip_words and len(potential_location) > 2:
                return potential_location
    
    return "Ok√§nd"

# Nyckelord f√∂r krig och konflikter
krig_keywords = [
    'krig', 'slag', 'strid', 'drabbning', 'konflikt', 'anfalla', 'anfall',
    'invasion', 'er√∂vr', 'bel√§gr', 'bel√§grade', 'arm√©', 'trupp', 'soldat',
    'viking', 'h√§rt√•g', 'plundra', 'brand', 'f√§ltt√•g', 'fred', 'fredsslut',
    'kapitulation', 'seger', 'nederlag', 'stupade', 'd√∂da', 'offer',
    'vapen', 'sv√§rd', 'kanon', 'flotta', 'sj√∂slag', 'landstigning',
    'f√∂rsvar', 'bef√§stning', 'borg', 'f√§stning', 'union', 'uppror',
    'revolt', 'mord', 'avr√§ttning', 'blodba', 'massaker', 'h√§rja',
    'bel√§grade', 'storm', 'er√∂vrade', 'intog', 'f√∂rst√∂rde', 'br√§nde',
    '√∂verfall', 'r√§d', 'plundr', 'brandskatt', 'gisslan', 'f√•ngar'
]

def contains_war_keywords(text):
    """Kontrollera om texten inneh√•ller krigsrelaterade nyckelord."""
    text_lower = text.lower()
    return any(keyword in text_lower for keyword in krig_keywords)

def extract_year(text):
    """Extrahera √•rtal fr√•n text (500-2000 e.Kr.)."""
    years = []
    
    # Leta efter explicita "e.Kr." f√∂rst
    matches_ek = re.findall(r'(\d{3,4})\s*e\.?[Kk]r', text)
    for match in matches_ek:
        year = int(match)
        if 500 <= year <= 2000:
            years.append(year)
    
    # Leta efter vanliga √•rtal (1000-1999 antas vara e.Kr.)
    matches_year = re.findall(r'\b(1\d{3})\b', text)
    for match in matches_year:
        year = int(match)
        if year not in years and 500 <= year <= 2000:
            years.append(year)
    
    # Leta efter 500-999 om de n√§mns i historisk kontext
    matches_early = re.findall(r'\b([5-9]\d{2})\b', text)
    for match in matches_early:
        year = int(match)
        # Bara l√§gg till om texten verkar handla om historia
        if year not in years and 500 <= year <= 999:
            if any(word in text.lower() for word in ['viking', 'vendel', 'medeltid', '√•rhundrade', 'tal']):
                years.append(year)
    
    return list(set(years))  # Ta bort dubletter

def add_event(year, title, description, source_url):
    """L√§gg till h√§ndelse om den inte redan finns."""
    if year < 500 or year > 2000:
        return False
    
    # Rensa beskrivningen
    description = ' '.join(description.split())  # Ta bort extra whitespace
    
    # Extrahera plats automatiskt fr√•n texten
    area = extract_location(description)
    
    # Unik nyckel: √•r + omr√•de + f√∂rsta 100 tecken av beskrivning
    key = f"{year}_{area}_{description[:100]}"
    
    if key in seen:
        return False
    seen.add(key)
    
    events.append({
        "year": year,
        "title": title,
        "description": description[:500].strip(),
        "area": area,
        "source_url": source_url
    })
    return True

def fetch_url(url, timeout=15):
    """H√§mta URL med felhantering."""
    try:
        response = requests.get(url, headers=headers, timeout=timeout)
        response.raise_for_status()
        return response
    except requests.exceptions.RequestException as e:
        print(f"    ‚ùå Fel vid h√§mtning: {e}")
        return None

# ===================
# 1. WIKIPEDIA - KRIG OCH KONFLIKTER
# ===================
print("=" * 70)
print("1. WIKIPEDIA - KRIG OCH KONFLIKTER")
print("=" * 70)

wiki_krig_sidor = {
    # √ñvergripande milit√§rhistoria
    "Sveriges_milit√§rhistoria": "Sverige",
    "Lista_√∂ver_slag_i_Sverige": "Sverige",
    "Lista_√∂ver_krig_som_Sverige_deltagit_i": "Sverige",
    
    # Tids√•ldrar
    "Vikingatiden": "Sverige",
    "Vendeltiden": "Sverige",
    "Sveriges_medeltid": "Sverige",
    "Kalmarunionen": "Sverige",
    "Stormaktstiden": "Sverige",
    "Svenska_frihetstiden": "Sverige",
    
    # Stora krig (kronologiskt)
    # Medeltida konflikter
    "√Ñldre_Vestg√∂talagens_krig": "V√§sterg√∂tland",
    "Slaget_vid_Fotevik": "Sk√•ne",
    "Slaget_vid_Gestilren": "Sverige",
    "Slaget_vid_Lena": "Sverige",
    "Slaget_vid_Sparrs√§tra": "Sverige",
    "Folkungarnas_uppror": "Sverige",
    "Hatarnas_uppror": "Sverige",
    
    # Kalmarunionens konflikter
    "Engelbrektupproret": "Sverige",
    "Engelbrekt_Engelbrektsson": "Sverige",
    "Slaget_vid_Brunkeberg": "Sverige",
    "Stockholms_blodbad": "Sverige",
    "Daljunkern": "Dalarna",
    
    # Vasatiden
    "Gustav_Vasas_befrielsekrig": "Sverige",
    "Dackeupproret": "Sm√•land",
    "Nils_Dacke": "Sm√•land",
    "Nordiska_sju√•rskriget": "Sverige",
    "Livl√§ndska_kriget": "Sverige",
    "Klubbekriget": "Sverige",
    
    # 1600-talets krig (Stormaktstiden)
    "Kalmarkriget": "Sverige",
    "De_la_Gardieska_f√§ltt√•get": "Sverige",
    "Polska_tronkrigen": "Sverige",
    "Trettio√•riga_kriget": "Sverige",
    "Torstenssonskriget": "Sverige",
    "Karl_X_Gustavs_f√∂rsta_danska_krig": "Sverige",
    "Karl_X_Gustavs_andra_danska_krig": "Sverige",
    "Karl_X_Gustavs_krig_mot_Polen": "Sverige",
    "Karl_X_Gustavs_ryska_krig": "Sverige",
    "Sk√•nska_kriget": "Sk√•ne",
    "Snapphanekrigen": "Sk√•ne",
    
    # 1700-talets krig
    "Stora_nordiska_kriget": "Sverige",
    "Pommerska_kriget": "Sverige",
    "Gustav_III:s_ryska_krig": "Sverige",
    "Teaterkriget": "Sverige",
    
    # 1800-talets krig
    "Finska_kriget": "Sverige",
    "Svensk-norska_kriget_1814": "Sverige",
    
    # Specifika slag
    "Slaget_vid_Brunkeberg": "Sverige",
    "Slaget_vid_Uppsala_1520": "Sverige",
    "Slaget_vid_Br√§nnkyrka": "Sverige",
    "Slaget_vid_St√•ngebro": "Sverige",
    "Slaget_vid_Kirkholm": "Sverige",
    "Slaget_vid_Breitenfeld_(1631)": "Tyskland",
    "Slaget_vid_L√ºtzen": "Tyskland",
    "Slaget_vid_Jankow": "B√∂hmen",
    "Slaget_vid_Warschau_(1656)": "Polen",
    "Slaget_vid_Lund": "Sk√•ne",
    "Slaget_vid_Landskrona": "Sk√•ne",
    "Slaget_vid_Narva": "Estland",
    "Slaget_vid_Klisz√≥w": "Polen",
    "Slaget_vid_Poltava": "Ukraina",
    "Slaget_vid_Helsingborg_(1710)": "Sk√•ne",
    "Slaget_vid_Gadebusch": "Tyskland",
    
    # Regionala historier med konflikter
    "Sk√•nes_historia": "Sk√•ne",
    "Gotlands_historia": "Gotland",
    "Bohusl√§ns_historia": "Bohusl√§n",
    "Blekinges_historia": "Blekinge",
    "Hallands_historia": "Halland",
    "J√§mtlands_historia": "J√§mtland",
    
    # Vikingah√§ndelser
    "Birka": "Sverige",
    "Ansgars_missioner": "Sverige",
    "Rurik": "Sverige",
    "Varangerna": "Sverige",
    "Ingvar_den_vittfarne": "Sverige",
    
    # Kungar och ledare (med krigshistoria)
    "Erik_Segers√§ll": "Sverige",
    "Olof_Sk√∂tkonung": "Sverige",
    "Anund_Jakob": "Sverige",
    "Erik_den_helige": "Sverige",
    "Birger_jarl": "Sverige",
    "Magnus_Ladul√•s": "Sverige",
    "Albrecht_av_Mecklenburg": "Sverige",
    "Karl_Knutsson_(Bonde)": "Sverige",
    "Kristian_II_av_Danmark": "Sverige",
    "Gustav_Vasa": "Sverige",
    "Erik_XIV": "Sverige",
    "Johan_III": "Sverige",
    "Karl_IX": "Sverige",
    "Gustav_II_Adolf": "Sverige",
    "Karl_X_Gustav": "Sverige",
    "Karl_XI": "Sverige",
    "Karl_XII": "Sverige",
    "Fredrik_I_av_Sverige": "Sverige",
    "Gustav_III": "Sverige",
    "Gustav_IV_Adolf": "Sverige",
}

for sida, region in wiki_krig_sidor.items():
    print(f"  H√§mtar: {sida[:50]}...")
    
    url = "https://sv.wikipedia.org/w/api.php"
    params = {
        "action": "parse",
        "page": sida,
        "format": "json",
        "prop": "text"
    }
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=15)
        data = response.json()
        
        if "error" in data:
            print(f"    ‚ùå Sidan finns inte")
            continue
        
        html = data["parse"]["text"]["*"]
        soup = BeautifulSoup(html, 'html.parser')
        
        # Ta bort referenser och fotnoter f√∂r renare text
        for ref in soup.find_all(['sup', 'span'], class_=['reference', 'mw-ref']):
            ref.decompose()
        
        count = 0
        for p in soup.find_all('p'):
            text = p.get_text()
            
            # Hoppa √∂ver korta stycken
            if len(text) < 50:
                continue
            
            # Kontrollera om texten inneh√•ller krigsrelaterade ord
            if not contains_war_keywords(text):
                continue
            
            years = extract_year(text)
            
            for year in years:
                # Skapa en mer beskrivande titel
                title = f"Krig/konflikt i {region} {year}"
                if add_event(year, title, text, f"https://sv.wikipedia.org/wiki/{sida}"):
                    count += 1
        
        if count > 0:
            print(f"    ‚úÖ {count} nya h√§ndelser")
        else:
            print(f"    ‚ö™ Inga nya h√§ndelser")
        
    except Exception as e:
        print(f"    ‚ùå Fel: {e}")
    
    time.sleep(0.3)  # Var sn√§ll mot Wikipedia

# ===================
# 2. SO-RUMMET
# ===================
print("\n" + "=" * 70)
print("2. SO-RUMMET")
print("=" * 70)

so_sidor = [
    "https://www.so-rummet.se/fakta-artiklar/vikingatiden-i-sverige",
    "https://www.so-rummet.se/fakta-artiklar/vikingarnas-historia",
    "https://www.so-rummet.se/fakta-artiklar/vikingatidens-samhalle-och-kultur",
    "https://www.so-rummet.se/fakta-artiklar/sveriges-medeltid",
    "https://www.so-rummet.se/fakta-artiklar/kalmarunionen",
    "https://www.so-rummet.se/fakta-artiklar/stockholms-blodbad",
    "https://www.so-rummet.se/fakta-artiklar/gustav-vasa",
    "https://www.so-rummet.se/fakta-artiklar/vasatiden-i-sverige",
    "https://www.so-rummet.se/fakta-artiklar/stormaktstiden",
    "https://www.so-rummet.se/fakta-artiklar/den-svenska-stormaktstidens-uppgang",
    "https://www.so-rummet.se/fakta-artiklar/den-svenska-stormaktstidens-fall",
    "https://www.so-rummet.se/fakta-artiklar/trettioariga-kriget",
    "https://www.so-rummet.se/fakta-artiklar/trettioariga-krigets-orsaker-och-bakgrund",
    "https://www.so-rummet.se/fakta-artiklar/karl-xii",
    "https://www.so-rummet.se/fakta-artiklar/stora-nordiska-kriget",
    "https://www.so-rummet.se/fakta-artiklar/frihetstiden-1719-1772",
    "https://www.so-rummet.se/fakta-artiklar/gustavianska-tiden",
]

for url in so_sidor:
    filename = url.split('/')[-1][:40]
    print(f"  H√§mtar: {filename}...")
    
    response = fetch_url(url)
    if not response:
        continue
    
    soup = BeautifulSoup(response.text, 'html.parser')
    article = soup.find('article') or soup.find('div', class_='article-content') or soup.find('main') or soup
    
    count = 0
    for p in article.find_all('p'):
        text = p.get_text()
        
        if len(text) < 50:
            continue
        
        if not contains_war_keywords(text):
            continue
        
        years = extract_year(text)
        
        for year in years:
            if add_event(year, f"Krig/konflikt {year}", text, url):
                count += 1
    
    if count > 0:
        print(f"    ‚úÖ {count} nya h√§ndelser")
    else:
        print(f"    ‚ö™ Inga nya h√§ndelser")
    
    time.sleep(1)

# ===================
# 3. POPUL√ÑR HISTORIA
# ===================
print("\n" + "=" * 70)
print("3. POPUL√ÑR HISTORIA")
print("=" * 70)

ph_sidor = [
    "https://popularhistoria.se/sveriges-historia/vikingatiden",
    "https://popularhistoria.se/sveriges-historia/medeltiden",
    "https://popularhistoria.se/sveriges-historia/vasatiden",
    "https://popularhistoria.se/sveriges-historia/stormaktstiden",
    "https://popularhistoria.se/sveriges-historia/frihetstiden",
    "https://popularhistoria.se/krig-drabbningar",
    "https://popularhistoria.se/krig-drabbningar/trettioariga-kriget",
    "https://popularhistoria.se/krig-drabbningar/slaget-vid-lund-1676",
    "https://popularhistoria.se/krig-drabbningar/slaget-vid-poltava",
    "https://popularhistoria.se/sveriges-historia/stormaktstiden/karl-xii",
    "https://popularhistoria.se/sveriges-historia/medeltiden/stockholms-blodbad",
    "https://popularhistoria.se/sveriges-historia/vikingatiden/vikingarna",
    "https://popularhistoria.se/sveriges-historia/stormaktstiden/gustav-ii-adolf",
]

for url in ph_sidor:
    filename = url.split('/')[-1][:40]
    print(f"  H√§mtar: {filename}...")
    
    response = fetch_url(url)
    if not response:
        continue
    
    soup = BeautifulSoup(response.text, 'html.parser')
    article = soup.find('article') or soup.find('main') or soup
    
    count = 0
    for p in article.find_all('p'):
        text = p.get_text()
        
        if len(text) < 50:
            continue
        
        if not contains_war_keywords(text):
            continue
        
        years = extract_year(text)
        
        for year in years:
            if add_event(year, f"Krig/konflikt {year}", text, url):
                count += 1
    
    if count > 0:
        print(f"    ‚úÖ {count} nya h√§ndelser")
    else:
        print(f"    ‚ö™ Inga nya h√§ndelser")
    
    time.sleep(1)

# ===================
# 4. HISTORISKA MUSEET
# ===================
print("\n" + "=" * 70)
print("4. HISTORISKA MUSEET")
print("=" * 70)

hm_sidor = [
    "https://historiska.se/utforska-historien/tidsaldrar/vikingatiden/",
    "https://historiska.se/utforska-historien/tidsaldrar/medeltiden/",
    "https://historiska.se/utforska-historien/kunskapsbank/vikingar/",
    "https://historiska.se/utforska-historien/kunskapsbank/vikingatidens-vapen/",
]

for url in hm_sidor:
    filename = url.split('/')[-2][:40]
    print(f"  H√§mtar: {filename}...")
    
    response = fetch_url(url)
    if not response:
        continue
    
    soup = BeautifulSoup(response.text, 'html.parser')
    article = soup.find('article') or soup.find('main') or soup
    
    count = 0
    for p in article.find_all('p'):
        text = p.get_text()
        
        if len(text) < 50:
            continue
        
        if not contains_war_keywords(text):
            continue
        
        years = extract_year(text)
        
        for year in years:
            if add_event(year, f"Krig/konflikt {year}", text, url):
                count += 1
    
    if count > 0:
        print(f"    ‚úÖ {count} nya h√§ndelser")
    else:
        print(f"    ‚ö™ Inga nya h√§ndelser")
    
    time.sleep(1)

# ===================
# 5. KUNGAHUSET
# ===================
print("\n" + "=" * 70)
print("5. KUNGAHUSET")
print("=" * 70)

kh_sidor = [
    "https://www.kungahuset.se/monarkin/kungarochregenter",
    "https://www.kungahuset.se/monarkin/monarkinisverige",
]

for url in kh_sidor:
    filename = url.split('/')[-1][:40]
    print(f"  H√§mtar: {filename}...")
    
    response = fetch_url(url)
    if not response:
        continue
    
    soup = BeautifulSoup(response.text, 'html.parser')
    article = soup.find('article') or soup.find('main') or soup
    
    count = 0
    for p in article.find_all('p'):
        text = p.get_text()
        
        if len(text) < 50:
            continue
        
        if not contains_war_keywords(text):
            continue
        
        years = extract_year(text)
        
        for year in years:
            if add_event(year, f"Krig/konflikt {year}", text, url):
                count += 1
    
    if count > 0:
        print(f"    ‚úÖ {count} nya h√§ndelser")
    else:
        print(f"    ‚ö™ Inga nya h√§ndelser")
    
    time.sleep(1)

# ===================
# 6. RIKSARKIVET
# ===================
print("\n" + "=" * 70)
print("6. RIKSARKIVET")
print("=" * 70)

ra_sidor = [
    "https://riksarkivet.se/krig",
    "https://riksarkivet.se/militaria",
    "https://sok.riksarkivet.se/trettioariga-kriget",
]

for url in ra_sidor:
    filename = url.split('/')[-1][:40]
    print(f"  H√§mtar: {filename}...")
    
    response = fetch_url(url)
    if not response:
        continue
    
    soup = BeautifulSoup(response.text, 'html.parser')
    article = soup.find('article') or soup.find('main') or soup
    
    count = 0
    for p in article.find_all('p'):
        text = p.get_text()
        
        if len(text) < 50:
            continue
        
        if not contains_war_keywords(text):
            continue
        
        years = extract_year(text)
        
        for year in years:
            if add_event(year, f"Krig/konflikt {year}", text, url):
                count += 1
    
    if count > 0:
        print(f"    ‚úÖ {count} nya h√§ndelser")
    else:
        print(f"    ‚ö™ Inga nya h√§ndelser")
    
    time.sleep(1)

# ===================
# 7. LIVRUSTKAMMAREN
# ===================
print("\n" + "=" * 70)
print("7. LIVRUSTKAMMAREN")
print("=" * 70)

lrk_sidor = [
    "https://livrustkammaren.se/sv/historia/",
    "https://livrustkammaren.se/sv/samlingarna/vapen/",
]

for url in lrk_sidor:
    filename = url.split('/')[-2][:40]
    print(f"  H√§mtar: {filename}...")
    
    response = fetch_url(url)
    if not response:
        continue
    
    soup = BeautifulSoup(response.text, 'html.parser')
    article = soup.find('article') or soup.find('main') or soup
    
    count = 0
    for p in article.find_all('p'):
        text = p.get_text()
        
        if len(text) < 50:
            continue
        
        if not contains_war_keywords(text):
            continue
        
        years = extract_year(text)
        
        for year in years:
            if add_event(year, f"Krig/konflikt {year}", text, url):
                count += 1
    
    if count > 0:
        print(f"    ‚úÖ {count} nya h√§ndelser")
    else:
        print(f"    ‚ö™ Inga nya h√§ndelser")
    
    time.sleep(1)

# ===================
# 8. ARM√âMUSEUM
# ===================
print("\n" + "=" * 70)
print("8. ARM√âMUSEUM")
print("=" * 70)

am_sidor = [
    "https://www.armemuseum.se/utforska/tidslinjen/",
    "https://www.armemuseum.se/utforska/artiklar/",
]

for url in am_sidor:
    filename = url.split('/')[-2][:40]
    print(f"  H√§mtar: {filename}...")
    
    response = fetch_url(url)
    if not response:
        continue
    
    soup = BeautifulSoup(response.text, 'html.parser')
    article = soup.find('article') or soup.find('main') or soup
    
    count = 0
    for p in article.find_all('p'):
        text = p.get_text()
        
        if len(text) < 50:
            continue
        
        if not contains_war_keywords(text):
            continue
        
        years = extract_year(text)
        
        for year in years:
            if add_event(year, f"Krig/konflikt {year}", text, url):
                count += 1
    
    if count > 0:
        print(f"    ‚úÖ {count} nya h√§ndelser")
    else:
        print(f"    ‚ö™ Inga nya h√§ndelser")
    
    time.sleep(1)

# ===================
# 9. SVENSKT MILIT√ÑRHISTORISKT BIBLIOTEK
# ===================
print("\n" + "=" * 70)
print("9. SVENSKT MILIT√ÑRHISTORISKT BIBLIOTEK (SMHB)")
print("=" * 70)

smhb_sidor = [
    "https://www.militarhistoria.se/artiklar/",
]

for url in smhb_sidor:
    filename = url.split('/')[-2][:40]
    print(f"  H√§mtar: {filename}...")
    
    response = fetch_url(url)
    if not response:
        continue
    
    soup = BeautifulSoup(response.text, 'html.parser')
    article = soup.find('article') or soup.find('main') or soup
    
    count = 0
    for p in article.find_all('p'):
        text = p.get_text()
        
        if len(text) < 50:
            continue
        
        if not contains_war_keywords(text):
            continue
        
        years = extract_year(text)
        
        for year in years:
            if add_event(year, f"Krig/konflikt {year}", text, url):
                count += 1
    
    if count > 0:
        print(f"    ‚úÖ {count} nya h√§ndelser")
    else:
        print(f"    ‚ö™ Inga nya h√§ndelser")
    
    time.sleep(1)

# ===================
# SPARA RESULTAT
# ===================
print("\n" + "=" * 70)
print("RESULTAT")
print("=" * 70)

df = pd.DataFrame(events)

if len(df) > 0:
    df = df.sort_values("year")
    df = df.drop_duplicates(subset=["year", "area", "description"])
    
    # Spara till CSV
    df.to_csv("krig_events.csv", index=False, encoding="utf-8")
    
    print(f"\n‚úÖ Totalt {len(df)} unika krigsh√§ndelser sparade till 'krig_events.csv'!")
    
    print(f"\nüìç F√ñRDELNING PER OMR√ÖDE:")
    print("-" * 40)
    area_counts = df["area"].value_counts()
    for area, count in area_counts.items():
        print(f"  {area}: {count}")
    
    print(f"\nüîó F√ñRDELNING PER K√ÑLLA:")
    print("-" * 40)
    source_counts = df["source_url"].apply(lambda x: x.split("/")[2]).value_counts()
    for source, count in source_counts.items():
        print(f"  {source}: {count}")
    
    print(f"\nüìù EXEMPEL P√Ö H√ÑNDELSER:")
    print("-" * 40)
    # Visa exempel fr√•n olika perioder
    sample_years = [600, 900, 1200, 1500, 1700]
    for target_year in sample_years:
        closest = df.iloc[(df['year'] - target_year).abs().argsort()[:1]]
        if not closest.empty:
            row = closest.iloc[0]
            print(f"\n  √Ör {row['year']} ({row['area']}):")
            print(f"    {row['description'][:150]}...")
else:
    print("\n‚ùå Inga h√§ndelser hittades.")
    print("   Kontrollera att du har internet√•tkomst till k√§llorna.")
    print("   Scriptet √§r designat att k√∂ras lokalt p√• din dator.")